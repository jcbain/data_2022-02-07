{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Trees\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import altair as alt\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_circles\n",
    "\n",
    "# pip install git+git://github.com/mgelbart/plot-classifier.git\n",
    "from plot_classifier import plot_classifier\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Trees\n",
    "\n",
    "![toy tree](../images/toytree.PNG)\n",
    "\n",
    "### Some Terminology\n",
    "\n",
    "![structure](../images/treestructure.PNG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_tree(X, y, model, predict_proba = False):\n",
    "    \n",
    "    # Join data for plotting\n",
    "    sample = (X.join(y))\n",
    "    # Create a mesh for plotting\n",
    "    step = (X.max() - X.min()) / 50\n",
    "    x1, x2 = np.meshgrid(np.arange(sample.min()[0]-step[0], sample.max()[0]+step[0], step[0]),\n",
    "                         np.arange(sample.min()[1]-step[1], sample.max()[1]+step[1], step[1]))\n",
    "\n",
    "    # Store mesh in dataframe\n",
    "    mesh_df = pd.DataFrame(np.c_[x1.ravel(), x2.ravel()], columns=['x1', 'x2'])\n",
    "\n",
    "    # Mesh predictions\n",
    "    if predict_proba:\n",
    "        mesh_df['predictions'] = model.predict_proba(mesh_df[['x1', 'x2']])[:, 0]\n",
    "        # Plot\n",
    "        base_plot = alt.Chart(mesh_df).mark_rect(opacity=0.5).encode(\n",
    "            x=alt.X('x1', bin=alt.Bin(step=step[0])),\n",
    "            y=alt.Y('x2', bin=alt.Bin(step=step[1])),\n",
    "            color=alt.Color('predictions', title='P(blue)', scale=alt.Scale(scheme='redblue'))\n",
    "        ).properties(\n",
    "            width=400,\n",
    "            height=400\n",
    "        )\n",
    "        return alt.layer(base_plot).configure_axis(\n",
    "            labelFontSize=20,\n",
    "            titleFontSize=20\n",
    "        ).configure_legend(\n",
    "            titleFontSize=20,\n",
    "            labelFontSize=20\n",
    "        )\n",
    "    else:\n",
    "        mesh_df['predictions'] = model.predict(mesh_df[['x1', 'x2']])\n",
    "        # Plot\n",
    "        scat_plot = alt.Chart(sample).mark_circle(\n",
    "            stroke='black',\n",
    "            opacity=1,\n",
    "            strokeWidth=1.5,\n",
    "            size=100\n",
    "        ).encode(\n",
    "            x=alt.X(X.columns[0], axis=alt.Axis(labels=True, ticks=True, title=X.columns[0])),\n",
    "            y=alt.Y(X.columns[1], axis=alt.Axis(labels=True, ticks=True, title=X.columns[1])),\n",
    "            color=alt.Color(y.columns[0])\n",
    "        )\n",
    "        base_plot = alt.Chart(mesh_df).mark_rect(opacity=0.5).encode(\n",
    "            x=alt.X('x1', bin=alt.Bin(step=step[0])),\n",
    "            y=alt.Y('x2', bin=alt.Bin(step=step[1])),\n",
    "            color=alt.Color('predictions', title='Legend')\n",
    "        ).properties(\n",
    "            width=400,\n",
    "            height=400\n",
    "        )\n",
    "        return alt.layer(base_plot, scat_plot).configure_axis(\n",
    "            labelFontSize=20,\n",
    "            titleFontSize=20\n",
    "        ).configure_legend(\n",
    "            titleFontSize=20,\n",
    "            labelFontSize=20\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Let's see how decision trees work\n",
    "- Get our data in\n",
    "- Train / validation split\n",
    "- Fit a **classification tree**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/cities_USA.csv', index_col=0)\n",
    "X = df.drop(columns=['vote'])\n",
    "y = df[['vote']]\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = DecisionTreeClassifier(max_depth=None)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## What did the classification tree do?\n",
    "- Found a good way to split and repeat\n",
    "\n",
    "\n",
    "Let's go ahead and visualize the decision boundaries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_tree(X_train, y_train, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can also print out a tree to see how the decisions were made. We'll go ahead and save this to a file and just bring it in to visualize it a bit better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import export_graphviz \n",
    "# conda install python-graphviz\n",
    "\n",
    "import graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dot_data = export_graphviz(model)\n",
    "graphviz.Source(export_graphviz(model,\n",
    "                                out_file=None,\n",
    "                                feature_names=X.columns,\n",
    "                                class_names=[\"red\", \"blue\"],\n",
    "                                impurity=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A look at our full tree\n",
    "\n",
    "![full tree](../images/graphviztree.PNG)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and our decision boundaries\n",
    "\n",
    "![decision boundaries](../images/decisionboundaries.gif)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## So how do we decide the split?\n",
    "- Basic idea is to pick a criterion (see [here](https://scikit-learn.org/stable/modules/tree.html#mathematical-formulation)) and then minimize it across possible splits.\n",
    "- Common one is Gini impurity\n",
    "\n",
    "### Gini Impurity\n",
    "\n",
    "First, Gini Impurity is the probability that a novel classification will be classified incorrectly. So, if we split the data off of some condition, what is the impurity of each of the new nodes? However, not all nodes are even, so can we weight our impurity of the new nodes to get at what is the best split to make?\n",
    "\n",
    "<img src='../images/gini.png' width=300>\n",
    "\n",
    "- $C$ is number of classes in target variable\n",
    "- $p$ is proportion of class $i$ in a group\n",
    "- tells us what is the probability of misclassifying an observation --> lower the better\n",
    "\n",
    "\n",
    "Full details here: https://towardsdatascience.com/gini-impurity-measure-dbd3878ead33\n",
    "\n",
    "![gini impurity](../images/giniimpurity.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Let's try writing some code for Gini Impurity for a given node\n",
    "\n",
    "The first thing we need to do is create a function to calculate the gini impurity of a node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vals = np.array(['yes', 'no', 'yes', 'no', 'yes', 'yes', 'no'])\n",
    "\n",
    "def calculate_gini_impurity(vals):\n",
    "    (unique_vals, counts) = np.unique(vals, return_counts=True)\n",
    "    num_vals = len(vals)\n",
    "    gini = 0\n",
    "    for i in range(len(unique_vals)):\n",
    "        num_class = counts[i]\n",
    "        gini = gini + ((num_class/num_vals) * (1 - num_class/num_vals))\n",
    "    return gini\n",
    "        \n",
    "        \n",
    "print(calculate_gini_impurity(vals))\n",
    "print(calculate_gini_impurity(np.array([1, 2])))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data \n",
    "\n",
    "path: `/src/data/does_james_eat.csv`\n",
    "description: some observations as to whether or not James's consumes food.\n",
    "\n",
    "Based off of whether or not James is hungry and whether or not they have Pop Tarts, can we predict whether James will eat?\n",
    "\n",
    "How should we split the first node?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eat = pd.read_csv(\"../data/does_james_eat.csv\")\n",
    "eat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But first, what if we were just to throw out a guess on whether or not James eat's food without any inputs? Well, that's simply calculating the impurity of the target `will_eat` for the entire dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_gini_impurity(eat['will_eat'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now split our data off of some condition. How about we split on the variable `is_hungry`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'will_eat'\n",
    "split = eat['is_hungry'] == 'yes';\n",
    "hungry = eat[split]\n",
    "not_hungry = eat[~split]\n",
    "\n",
    "print(\"hungry == yes\")\n",
    "print(hungry)\n",
    "print(\"hungry == no\")\n",
    "print(not_hungry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(calculate_gini_impurity(hungry['will_eat']))\n",
    "print(calculate_gini_impurity(not_hungry['will_eat']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's caculate the impurity of the split of the sum of the weighted impurities for the new nodes. Whatever split minimizes this value is where we split this node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_impurity(data, target_var, split_var, split_condition):\n",
    "    num_samples = data.shape[0]\n",
    "    split = data[split_var] == split_condition\n",
    "    split_data0 = data[split]\n",
    "    split_data1 = data[~split]\n",
    "    weight0 = split_data0.shape[0] / num_samples\n",
    "    weight1 = split_data1.shape[0] / num_samples\n",
    "    gini0 = calculate_gini_impurity(split_data0[target_var])\n",
    "    gini1 = calculate_gini_impurity(split_data1[target_var])\n",
    "    return weight0 * gini0 + weight1 * gini1\n",
    "\n",
    "print(\"gini impurity for has poptarts\")\n",
    "print(calculate_impurity(eat, 'will_eat', 'has_poptarts', 'yes'))\n",
    "\n",
    "print(\"gini impurity for is hungry\")\n",
    "print(calculate_impurity(eat, 'will_eat', 'is_hungry', 'yes'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Regression trees\n",
    "Imagine that our output (target) variable was continuous instead of discrete. In other words, we have a regression problem instead of a classification problem. Well, trees are an effective method in these scenarios as well.\n",
    "\n",
    "A couple of things:\n",
    "- Less intuitive, but same idea\n",
    "- Instead of Gini, we use something that works for regression, like MSE (think residuals)\n",
    "\n",
    "### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the sake of example, we're going to go ahead and create some dummy data just for demonstration purposes. Here, we'll have two features and a target that we are trying to predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(333)\n",
    "df = pd.DataFrame({'feature_1': np.random.randint(0, 10, (6,)),\n",
    "                   'feature_2': np.random.randint(0, 10, (6,)),\n",
    "                   'target': np.random.randint(0, 10, (6,))})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns='target')\n",
    "y = df['target']\n",
    "model = DecisionTreeRegressor(max_depth=3).fit(X, y)\n",
    "dot_data = export_graphviz(model)\n",
    "graphviz.Source(export_graphviz(model,\n",
    "                                out_file=None,\n",
    "                                feature_names=X.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Visualizing the First cut - regression tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "![regression tree](../images/graphviztree2.PNG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scatter = alt.Chart(df).mark_circle(\n",
    "    size=150,\n",
    "    opacity=1,\n",
    "    stroke='black',\n",
    "    strokeWidth=1\n",
    ").encode(\n",
    "    x=alt.X('feature_1', title='feature_1'),\n",
    "    y=alt.Y('feature_2', title='feature_2'),\n",
    "    color='target')\n",
    "text = scatter.mark_text(\n",
    "    align='left',\n",
    "    baseline='middle',\n",
    "    fontSize = 20,\n",
    "    dx=8\n",
    ").encode(\n",
    "    text='target')\n",
    "split = alt.Chart(df).mark_rule().encode(\n",
    "    x='a:Q',\n",
    "    size=alt.SizeValue(2),\n",
    "    color=alt.ColorValue(\"red\")\n",
    ").transform_calculate(\n",
    "    a=\"6.5\"\n",
    ")\n",
    "alt.layer(scatter, text, split).configure_axis(\n",
    "    labelFontSize=20,\n",
    "    titleFontSize=20\n",
    ").configure_legend(\n",
    "    titleFontSize=20,\n",
    "    labelFontSize=20\n",
    ").properties(\n",
    "    width=300,\n",
    "    height=300\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Decision trees, pros and cons\n",
    "### Advantages:\n",
    "- Simple to understand and to interpret. Trees can be visualised.\n",
    "- Requires little data preparation. Doesn't require data normalisation.\n",
    "- Can handle multi-class classification well.\n",
    "\n",
    "### Disadvantages:\n",
    "- Tendency to overfit with overly complex trees that don't generalize well; pruning techniques (e.g., minimum number of samples required at a leaf node, maximum depth of tree) is needed to avoid the problem\n",
    "- Decision trees can be unstable because small variations in the data might result in a completely different tree being generated; mitigated through ensembles (more on this soon)\n",
    "- They suffer from an inherent instability, since due to their hierarchical nature, the effect of an error in the top splits propagate down to all of the splits below.\n",
    "- Is a \"greedy\" algorithm. Each node is only locally optimal which cannot gaurantee globally optimal tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forests\n",
    "\n",
    "![random forests](../images/randomforest1.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imagine the following scenario\n",
    "\n",
    "You want to be able to be able to classify someone's fast food preference based off some questions. Perhaps, you ask questions such as \"are you a vegetarian/vegan?\", \"do you like hamburgers?\", \"do you like spicy food?\" And perhaps the range of target responses are \"McDonalds\", \"Chipotle\" and \"KFC\". \n",
    "\n",
    "- A *decision tree* would be like going out to Times Square and asking everyone **all** of those questions and getting their favorite fast food restaurant as a response. Then we can build a model off of all of their responses.\n",
    "\n",
    "- A *random forest* is like having a set of interviewers and each interviewer only selects a subset of the questions to ask the people they go up to. From this each of these interviewers, we build a tree and when we get new inputs, we ask each interviewer what their tree would predict and we take the average response as our response. \n",
    "    - note: a single individual can be sampled by many interviewers.\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### General idea:\n",
    "   - `fit` a diverse set of classifiers by **injecting randomness** in the classifier construction\n",
    "   - `predict` by taking the average of predictions given by individual classifiers\n",
    "\n",
    "### How do we inject randomness in the classifier construction? \n",
    "   1. Data: Build each tree on a bootstrap sample (i.e., a sample drawn **with replacement** from the training set)\n",
    "   2. Features: Consider a random subset of features at each split (`RandomForestClassifier`)\n",
    "        \n",
    "**The intuition here is the wisdom of crowds**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bootstrapping samples\n",
    "\n",
    "<img src='../images/bootstrapping.PNG' width='300'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The random forest classifier \n",
    "\n",
    "- Create a collection (ensemble) of trees. Grow each tree on an independent bootstrap sample from the data.\n",
    "- At each node:\n",
    "    - Randomly select a subset of features out of all features (independently for each node)\n",
    "    - Find the best split on the selected features\n",
    "    - Grow the trees to maximum depth\n",
    "- Vote between the trees to get predictions for new data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Random Forest Training\n",
    "- Showing feature subset\n",
    "\n",
    "<img src='../images/random-forest-features.jpg'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Random Forest Prediction\n",
    "<img src='../images/random-forest-predict.jpg'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_num_tree_plot(X_train, y_train, X_test, y_test, num_trees):\n",
    "    \"\"\"\n",
    "    Make number of trees vs error rate plot for RandomForestClassifier\n",
    "   \n",
    "    Parameters\n",
    "    ----------\n",
    "    model: sklearn classifier model\n",
    "        The sklearn model\n",
    "    X_train: numpy.ndarray        \n",
    "        The X part of the train set\n",
    "    y_train: numpy.ndarray\n",
    "        The y part of the train set    \n",
    "    X_test: numpy.ndarray        \n",
    "        The X part of the test/validation set\n",
    "    y_test: numpy.ndarray\n",
    "        The y part of the test/validation set    \n",
    "    num_trees: int\n",
    "        The value for `n_estimators` argument of RandomForestClassifier\n",
    "    Returns\n",
    "    -------\n",
    "        None\n",
    "        Shows the number of trees vs error rate plot\n",
    "            \n",
    "    \"\"\"    \n",
    "    train_err = []\n",
    "    test_err = []\n",
    "    for ntree in num_trees:\n",
    "        model = RandomForestClassifier(n_estimators=ntree)\n",
    "        model.fit(X_train, y_train)\n",
    "        train_err.append(1-model.score(X_train, y_train))\n",
    "        test_err.append(1-model.score(X_test, y_test))\n",
    "\n",
    "    plt.semilogx(num_trees,train_err,label=\"train\");\n",
    "    plt.semilogx(num_trees,test_err,label=\"test\");\n",
    "    plt.legend();\n",
    "    plt.xlabel('number of trees');\n",
    "    plt.ylabel('error rate');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Beating the fundamental tradeoff...\n",
    "\n",
    "- Decreasing training error and not increasing test error.\n",
    "- This is the promise of ensembles, though it's not guaranteed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_num_tree_plot(X_train, np.ravel(y_train), X_val, np.ravel(y_val), (1,5,10,25,50,100,200,500))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Random Forests summary\n",
    "\n",
    "- Accuracy\n",
    "    - Usually more accurate compared to decision trees, usually one of the best performing off-the-shelf classifiers\n",
    "- Speed\n",
    "    - Slower than decision trees because we are fitting multiple trees \n",
    "    - But can easily parallelize training because all trees are independent of each other - take seperate data and features \n",
    "- Overfitting\n",
    "    - No depth limit decision tree tends to overfit\n",
    "    - Random forests are less likely to overfit\n",
    "- Interpretability\n",
    "    - Decision trees are more interpretable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Ensembling - why?\n",
    "- Weak learners (or base models) are models that can be used as building blocks for designing more complex models\n",
    "- By combining several weak learners together, we can try to reduce bias and/or variance of weak learners\n",
    "- The ensemble model could have better performance - Kaggle competition winning models are usually ensemble methods\n",
    "\n",
    "### Some disadvantages:\n",
    "- Ensembling increases computational time to fit and predict\n",
    "- Also decreases interpretability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## More Ensemble Methods\n",
    "\n",
    "### Bagging (Bootstrap and Aggregate)\n",
    "<img src='../images/bagging.PNG' width='700'>\n",
    "\n",
    "- Random forest is an example of this\n",
    "- Same type of weak model used (e.g., trees), models learned in parallel, combines them in a deterministic process (e.g., averaging)\n",
    "\n",
    "\n",
    "### Boosting (will show example)\n",
    "<img src='../images/boosting.PNG' width='700'>\n",
    "\n",
    "- Add one \"learner\" (i.e. model) at a time, which addresses the \"shortcomings\" of the current ensemble.\n",
    "- Unlike averaging, ensemble is created *_during training_*, not after. The process is sequential.\n",
    "- Example: `AdaBoost`, `XGBoost`, `LGBM`\n",
    "\n",
    "\n",
    "### Stacking (will show example)\n",
    "<img src='../images/stacking.PNG' width='700'>\n",
    "\n",
    "- Usually with heterogeneous (different base model types) models\n",
    "- Each model learns indepedently and is combined using a voting model\n",
    "\n",
    "\n",
    "src = https://towardsdatascience.com/ensemble-methods-bagging-boosting-and-stacking-c9214a10a205"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Load smaller version of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/citiesSmall.pkl\", \"rb\") as f:\n",
    "    data = pickle.load(f)\n",
    "    X_train = data['X']\n",
    "    y_train = data['y']\n",
    "\n",
    "    X_val = data['Xtest']\n",
    "    y_val = data['ytest']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Boosting - one example library\n",
    "- `AdaBoost`: Adaptive Boosting\n",
    "\n",
    "<img src='../images/adaboost.PNG'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Let's generate some fake data\n",
    "\n",
    "# generate blobs with fixed random generator\n",
    "n = 100\n",
    "n_classes = 2\n",
    "X, y = make_circles(n_samples=n, random_state = 122)\n",
    "\n",
    "X_train_circ, X_test_circ, y_train_circ, y_test_circ = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# How does the data look like? \n",
    "plt.scatter(*X_train_circ.T, c=y_train_circ, marker='.', cmap='Dark2');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble = AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=2), n_estimators = 4)\n",
    "ensemble.fit(X_train_circ, y_train_circ);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Combine weak learners \n",
    "plt.figure(figsize=(20,20))\n",
    "count = 0\n",
    "weights = ensemble.estimator_weights_\n",
    "for estimator in ensemble.estimators_: # needs scikit-learn-0.20\n",
    "    plt.subplot(4,2,count+1)\n",
    "    plot_classifier(X_train_circ, y_train_circ, estimator, ax=plt.gca());\n",
    "    tr_err = (1 - estimator.score(X_train_circ, y_train_circ))\n",
    "    te_err = (1 - estimator.score(X_test_circ, y_test_circ))\n",
    "    title = 'Round: %i; Train_error: %0.3f; Test error: %0.3f; estimator weight: %0.3f'%(count+1, tr_err, te_err, weights[count])\n",
    "    plt.title(title);\n",
    "    count += 1\n",
    "    \n",
    "tr_err = (1 - ensemble.score(X_train_circ, y_train_circ))\n",
    "te_err = (1 - ensemble.score(X_test_circ, y_test_circ))\n",
    "title = 'Ensemble model; Train_error: %0.3f; Test error: %0.3f'%(tr_err, te_err)\n",
    "plt.subplot(4,2,count)\n",
    "plt.title(title)\n",
    "plot_classifier(X_train_circ, y_train_circ, ensemble, ax=plt.gca());        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Stacking - code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import VotingClassifier  #meta model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a simple voting classifier using scikit-learn's VotingClassifier\n",
    "\n",
    "classifiers = {\n",
    "    \"Decision tree\"         : DecisionTreeClassifier(max_depth=5),\n",
    "    \"KNN\"                   : KNeighborsClassifier(),\n",
    "    \"Naive Bayes\"           : GaussianNB(),\n",
    "    \"Logistic Regression\"   : LogisticRegression(),\n",
    "}\n",
    "\n",
    "\n",
    "ensemble = VotingClassifier(classifiers.items(), voting=\"soft\")\n",
    "\n",
    "# note: sklearn doesn't seem to support passing pre-trained classifiers into VotingClassifier\n",
    "ensemble.fit(X_train, np.ravel(y_train));\n",
    "\n",
    "print('Ensemble performance: \\n')\n",
    "print(\"Training error:   %.2f\" % (1-ensemble.score(X_train, np.ravel(y_train))))\n",
    "print(\"Validation error: %.2f\" % (1-ensemble.score(X_val, np.ravel(y_val))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## What's the performance of individual classifiers in the ensemble?\n",
    "for name, estimator in ensemble.named_estimators_.items(): # needs scikit-learn-0.20\n",
    "    tr_err = (1 - estimator.score(X_train, np.ravel(y_train)))\n",
    "    te_err = (1 - estimator.score(X_val, np.ravel(y_val)))\n",
    "    print('%s: Train_error: %0.3f; Test error: %0.3f'%(name, tr_err, te_err))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,16))\n",
    "count = 1\n",
    "for name, estimator in ensemble.named_estimators_.items(): # needs scikit-learn-0.20\n",
    "    plt.subplot(3,2,count)\n",
    "    plot_classifier(X_train, y_train, estimator, ax=plt.gca());\n",
    "    tr_err = (1 - estimator.score(X_train, y_train))\n",
    "    te_err = (1 - estimator.score(X_val, y_val))\n",
    "    title = '%s: Train_error: %0.3f; Test error: %0.3f'%(name, tr_err, te_err)    \n",
    "    plt.title(title);\n",
    "    count += 1\n",
    "    \n",
    "plt.subplot(3,2,6)\n",
    "plot_classifier(X_train, y_train, ensemble, ax=plt.gca());\n",
    "tr_err = 1 - ensemble.score(X_train, y_train)\n",
    "te_err = 1 - ensemble.score(X_val, y_val)\n",
    "title = '%s; Train_error: %0.3f; Test error: %0.3f'%('Ensemble', tr_err, te_err)    \n",
    "plt.title(title);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
